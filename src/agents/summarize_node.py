import logging
import os
from langchain_chroma import Chroma
from langchain_ollama import ChatOllama, OllamaEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
from src.vectordb.embedding import get_embedding_model
from langchain_google_genai import ChatGoogleGenerativeAI
import os 

# Env yÃ¼kle
load_dotenv()

# Logger
logger = logging.getLogger(__name__)

# --- 1. AYARLAR ---
DB_PATH = "./chromadb_summaries"  # Ã–zetlerin olduÄŸu ayrÄ± DB
COLLECTION_NAME = "legal_summaries"
MODEL_NAME = "gemma3:4b-it-qat"


load_dotenv()

# --- API KEY ve MODEL ADI KONTROLÃœ ---
google_api_key = os.getenv("GOOGLE_API_KEY")
gemini_model_name = os.getenv("GEMINI_MODEL_NAME", "gemini-2.0-flash-lite") # VarsayÄ±lan: 1.5-flash

if not google_api_key:
    logger.error("ğŸš¨ GOOGLE_API_KEY bulunamadÄ±! LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    # ProgramÄ±n burada durmasÄ±nÄ± istersen:
    # sys.exit(1) 
else:
    logger.info(f"ğŸ”‘ API Key yÃ¼klendi. Hedef Model: {gemini_model_name}")

# --- 3. MODEL AYARLARI ---

# ANALÄ°Z ve CEVAP Ä°Ã‡Ä°N: .env'den gelen modeli kullanÄ±yoruz
llm = ChatGoogleGenerativeAI(
    model=gemini_model_name,
    temperature=0,
    max_retries=2,
    google_api_key=google_api_key 
)

# --- 2. BAÄLANTI FONKSÄ°YONLARI ---
def get_summary_db():
    """Ã–zet veritabanÄ±na baÄŸlanÄ±r."""
    if not os.path.exists(DB_PATH):
        logger.warning("âš ï¸ Ã–zet veritabanÄ± bulunamadÄ±! vectorize.py ile Ã¶zet oluÅŸturulmalÄ±.")
        return None
        
    embedding_function = get_embedding_model()

    
    return Chroma(
        persist_directory=DB_PATH,
        embedding_function=embedding_function,
        collection_name=COLLECTION_NAME
    )

# --- 3. SUMMARIZE NODE (DÃœÄÃœM) ---
def summarize_node(state: dict):
    """
    Supervisor 'Q3' dediÄŸinde Ã§alÄ±ÅŸan fonksiyon.
    1. KullanÄ±cÄ± sorusuna gÃ¶re en alakalÄ± Ã¶zeti 'Mini-Retriever' ile bulur.
    2. Gemma 3 ile bu Ã¶zeti kullanÄ±cÄ±ya sunar.
    """
    question = state["question"]
    logger.info(f"ğŸ“ [SUMMARIZER] Ã–zetleme modu devrede: {question}")
    
    # A. VeritabanÄ±na BaÄŸlan
    db = get_summary_db()
    
    context_text = ""
    
    if db:
        # B. Mini-Retriever: Soruyla en alakalÄ± 3 Ã¶zeti getir
        # EÄŸer kullanÄ±cÄ± "KVKK" dediyse KVKK Ã¶zeti en Ã¼ste gelir.
        # EÄŸer "Neler var?" dediyse genel baÅŸlÄ±klar gelir.
        try:
            results = db.similarity_search(question, k=3)
            
            # Gelen dÃ¶kÃ¼manlarÄ± birleÅŸtir
            for i, doc in enumerate(results):
                source = doc.metadata.get("source", "Bilinmiyor")
                context_text += f"\n--- BELGE: {source} ---\n{doc.page_content}\n"
                
            logger.info(f"ğŸ“š {len(results)} adet ilgili Ã¶zet bulundu.")
            
        except Exception as e:
            logger.error(f"Ã–zet ararken hata: {e}")
            context_text = "VeritabanÄ± hatasÄ± nedeniyle Ã¶zetlere eriÅŸilemedi."
    else:
        context_text = "Sistemde henÃ¼z hazÄ±r Ã¶zet bulunmuyor. LÃ¼tfen belgeleri indeksleyin."

    # C. Sentezleme (Synthesis): Gemma 3 CevabÄ± YazÄ±yor
    # Not: Burada temperature biraz aÃ§Ä±k olabilir (0.3), daha doÄŸal konuÅŸsun.
    #llm = ChatOllama(model=MODEL_NAME, temperature=0.3)
    
    prompt_template = ChatPromptTemplate.from_template(
        """Sen yardÄ±msever bir Hukuk AsistanÄ±sÄ±n. KullanÄ±cÄ± genel bir bilgi veya Ã¶zet istedi.
        AÅŸaÄŸÄ±da veritabanÄ±mÄ±zdaki ilgili belgelerin HAZIR Ã–ZETLERÄ° var.
        
        GÃ–REVÄ°N:
        Bu Ã¶zetleri kullanarak kullanÄ±cÄ±nÄ±n sorusuna net, anlaÅŸÄ±lÄ±r ve toparlayÄ±cÄ± bir cevap ver.
        EÄŸer kullanÄ±cÄ± "neler var?" gibi genel bir ÅŸey sorduysa belgeleri listele ve kÄ±saca iÃ§eriklerinden bahset.
        
        --- BULUNAN Ã–ZETLER ---
        {context}
        -----------------------
        
        KULLANICI SORUSU: {question}
        
        CEVAP:"""
    )
    
    chain = prompt_template | llm
    response = chain.invoke({"context": context_text, "question": question})
    
    logger.info("âœ… Ã–zet cevabÄ± Ã¼retildi.")
    
    # State'i gÃ¼ncelle ve response'u dÃ¶n
    return {"response": response.content}